{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kommentare füge ich noch hinzu! Erstmal nur der Code.\n",
    "### Auch die Reihenfolge kann sich noch ändern\n",
    "#### Wichtig ist, dass alle Zellen über einer Zelle ausgeführt werden müssen, damit die Zellen darunter funktionieren!\n",
    "#### Außerdem, können die lambda-Methoden eine Weile dauern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_data = pd.read_csv('resources/boston_2018.csv')\n",
    "boston_2018_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(boston_2018_data)-len(boston_2018_data.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_data_clean = boston_2018_data.dropna(axis=0)\n",
    "boston_2018_data_clean.head(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(x):\n",
    "    return x.split('.')[0]\n",
    "\n",
    "boston_2018_data_clean['start_time'] = boston_2018_data_clean['start_time'].apply(lambda x: clean_date(x))\n",
    "boston_2018_data_clean['end_time'] = boston_2018_data_clean['end_time'].apply(lambda x: clean_date(x))\n",
    "boston_2018_data_clean.head(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(x):\n",
    "    return datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").date()\n",
    "\n",
    "def get_weekday(x):\n",
    "    return datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").weekday()\n",
    "\n",
    "def get_hour(x):\n",
    "    return datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").hour\n",
    "\n",
    "def get_month(x):\n",
    "    return datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_data_clean.reset_index(drop=True)\n",
    "boston_2018_data_clean['date'] = boston_2018_data_clean['start_time'].apply(lambda x: get_date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_data_clean['weekday'] = boston_2018_data_clean['start_time'].apply(lambda x: get_weekday(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_data_clean['hour'] = boston_2018_data_clean['start_time'].apply(lambda x: get_hour(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_data_clean['month'] = boston_2018_data_clean['start_time'].apply(lambda x: get_month(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_data_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_stations = pd.read_csv('resources/current_bluebikes_stations.csv')\n",
    "bike_stations.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bike_stations) - len(bike_stations.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_stations.columns = bike_stations.iloc[0]\n",
    "bike_stations.drop(bike_stations.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_start_geodata = pd.merge(boston_2018_data_clean, bike_stations[['Name','Latitude', 'Longitude', 'District']], left_on=\"start_station_name\", right_on=\"Name\", how=\"left\")\n",
    "boston_2018_start_geodata = boston_2018_start_geodata.rename(columns = {'Latitude': 'latitude_start', 'Longitude': 'longitude_start', \"District\": \"district_start\"})\n",
    "boston_2018_start_geodata['start_coordinates'] = list(zip(boston_2018_start_geodata[\"latitude_start\"],boston_2018_start_geodata[\"longitude_start\"]))\n",
    "del boston_2018_start_geodata['Name']\n",
    "\n",
    "boston_2018_trip_geodata = pd.merge(boston_2018_start_geodata, bike_stations[['Name','Latitude', 'Longitude', 'District']], left_on=\"end_station_name\", right_on=\"Name\", how=\"left\")\n",
    "boston_2018_trip_geodata = boston_2018_trip_geodata.rename(columns = {'Latitude': 'latitude_end', 'Longitude': 'longitude_end', \"District\": \"district_end\"})\n",
    "boston_2018_trip_geodata['end_coordinates'] = list(zip(boston_2018_trip_geodata[\"latitude_end\"],boston_2018_trip_geodata[\"longitude_end\"]))\n",
    "del boston_2018_trip_geodata['Name']\n",
    "\n",
    "boston_2018_trip_geodata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(boston_2018_trip_geodata)-len(boston_2018_trip_geodata.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_trip_geodata_clean = boston_2018_trip_geodata.dropna()\n",
    "len(boston_2018_trip_geodata_clean)-len(boston_2018_trip_geodata_clean.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_weather = pd.read_csv('resources/weather_hourly_boston.csv')\n",
    "boston_weather.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(boston_weather) - len(boston_weather.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_weather_clean = boston_weather.dropna()\n",
    "len(boston_weather_clean) - len(boston_weather_clean.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_weather_clean.reset_index(drop=True)\n",
    "pd.options.mode.chained_assignment = None\n",
    "boston_weather_clean['date'] = boston_weather_clean['date_time'].apply(lambda x:get_date(x))\n",
    "boston_weather_clean['hour'] = boston_weather_clean['date_time'].apply(lambda x:get_hour(x))\n",
    "boston_weather_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_trip_geodata_with_temp = pd.merge(boston_2018_trip_geodata_clean, \n",
    "                                              boston_weather_clean[['max_temp','min_temp', 'precip', 'date', 'hour']],\n",
    "                                              on=['date', 'hour'], how=\"left\")\n",
    "boston_2018_trip_geodata_with_temp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(boston_2018_trip_geodata_with_temp)-len(boston_2018_trip_geodata_with_temp.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_trip_geodata_with_temp_clean = boston_2018_trip_geodata_with_temp.dropna()\n",
    "len(boston_2018_trip_geodata_with_temp_clean)-len(boston_2018_trip_geodata_with_temp_clean.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geographical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "from folium.plugins import HeatMapWithTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into four datasets, based on the month, and then visualize amount of start and end districts of trips for each of these datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 4, sharey=True, figsize=(20, 10))\n",
    "\n",
    "sns.countplot(x=\"district_start\",data=boston_2018_trip_geodata_clean[boston_2018_trip_geodata_clean[\"month\"] < 4], ax=axes[0][0],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_start\",data=boston_2018_trip_geodata_clean[(boston_2018_trip_geodata_clean[\"month\"] >= 4) & (boston_2018_trip_geodata_clean[\"month\"] < 10)], ax=axes[0][1],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_start\",data=boston_2018_trip_geodata_clean[(boston_2018_trip_geodata_clean[\"month\"] >= 7) & (boston_2018_trip_geodata_clean[\"month\"] < 10)], ax=axes[0][2],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_start\",data=boston_2018_trip_geodata_clean[(boston_2018_trip_geodata_clean[\"month\"] >= 10) & (boston_2018_trip_geodata_clean[\"month\"] < 13)], ax=axes[0][3],palette=\"OrRd\")\n",
    "\n",
    "sns.countplot(x=\"district_end\",data=boston_2018_trip_geodata_clean[boston_2018_trip_geodata_clean[\"month\"] < 4], ax=axes[1][0],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_end\",data=boston_2018_trip_geodata_clean[(boston_2018_trip_geodata_clean[\"month\"] >= 4) & (boston_2018_trip_geodata_clean[\"month\"] < 10)], ax=axes[1][1],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_end\",data=boston_2018_trip_geodata_clean[(boston_2018_trip_geodata_clean[\"month\"] >= 7) & (boston_2018_trip_geodata_clean[\"month\"] < 10)], ax=axes[1][2],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_end\",data=boston_2018_trip_geodata_clean[(boston_2018_trip_geodata_clean[\"month\"] >= 10) & (boston_2018_trip_geodata_clean[\"month\"] < 13)], ax=axes[1][3],palette=\"OrRd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualing amount of trips started in a district and amount of trips ended there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into four, based on the time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_0_to_6 = boston_2018_trip_geodata_clean[boston_2018_trip_geodata_clean[\"hour\"] < 6]\n",
    "boston_2018_6_to_12 = boston_2018_trip_geodata_clean[(boston_2018_trip_geodata_clean[\"hour\"] >= 6) & (boston_2018_trip_geodata_clean[\"hour\"] < 12)]\n",
    "boston_2018_12_to_18 = boston_2018_trip_geodata_clean[(boston_2018_trip_geodata_clean[\"hour\"] >= 12) & (boston_2018_trip_geodata_clean[\"hour\"] < 18)]\n",
    "boston_2018_18_to_24 = boston_2018_trip_geodata_clean[(boston_2018_trip_geodata_clean[\"hour\"] >= 18) & (boston_2018_trip_geodata_clean[\"hour\"] < 24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 4, sharey=True, figsize=(20, 10))\n",
    "\n",
    "sns.countplot(x=\"district_start\",data=boston_2018_0_to_6, ax=axes[0][0],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_start\",data=boston_2018_6_to_12, ax=axes[0][1],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_start\",data=boston_2018_12_to_18, ax=axes[0][2],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_start\",data=boston_2018_18_to_24, ax=axes[0][3],palette=\"OrRd\")\n",
    "\n",
    "\n",
    "sns.countplot(x=\"district_end\",data=boston_2018_0_to_6, ax=axes[1][0],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_end\",data=boston_2018_6_to_12, ax=axes[1][1],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_end\",data=boston_2018_12_to_18, ax=axes[1][2],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_end\",data=boston_2018_18_to_24, ax=axes[1][3],palette=\"OrRd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing number of trips started in a district with number of trips ended there and calculate the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_0_to_6_start_count = boston_2018_0_to_6.groupby('district_start').count()\n",
    "boston_2018_6_to_12_start_count = boston_2018_6_to_12.groupby('district_start').count()\n",
    "boston_2018_12_to_18_start_count = boston_2018_12_to_18.groupby('district_start').count()\n",
    "boston_2018_18_to_24_start_count = boston_2018_18_to_24.groupby('district_start').count()\n",
    "\n",
    "boston_2018_0_to_6_end_count = boston_2018_0_to_6.groupby('district_end').count()\n",
    "boston_2018_6_to_12_end_count = boston_2018_6_to_12.groupby('district_end').count()\n",
    "boston_2018_12_to_18_end_count = boston_2018_12_to_18.groupby('district_end').count()\n",
    "boston_2018_18_to_24_end_count = boston_2018_18_to_24.groupby('district_end').count()\n",
    "\n",
    "boston_2018_0_to_6_change_count = boston_2018_0_to_6_start_count - boston_2018_0_to_6_end_count\n",
    "boston_2018_6_to_12_change_count = boston_2018_6_to_12_start_count - boston_2018_6_to_12_end_count\n",
    "boston_2018_12_to_18_change_count = boston_2018_12_to_18_start_count - boston_2018_12_to_18_end_count\n",
    "boston_2018_18_to_24_change_count = boston_2018_18_to_24_start_count - boston_2018_18_to_24_end_count\n",
    "boston_2018_0_to_6_change_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the difference per district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 4, sharey=True, figsize=(20, 10))\n",
    "\n",
    "axes[0].set_title(\"Supply change between 0 and 6 am\")\n",
    "axes[1].set_title(\"Supply change between 6 and 12 am\")\n",
    "axes[2].set_title(\"Supply change between 12 am and 6 pm\")\n",
    "axes[3].set_title(\"Supply change between 6 and 12 pm\")\n",
    "\n",
    "sns.barplot(x = boston_2018_0_to_6_change_count.index, y=\"start_time\", data=boston_2018_0_to_6_change_count, ax=axes[0],palette=\"OrRd\")\n",
    "sns.barplot(x=boston_2018_6_to_12_change_count.index, y=\"start_time\", data=boston_2018_6_to_12_change_count, ax=axes[1],palette=\"OrRd\")\n",
    "sns.barplot(x=boston_2018_12_to_18_change_count.index, y=\"start_time\", data=boston_2018_12_to_18_change_count, ax=axes[2],palette=\"OrRd\")\n",
    "sns.barplot(x=boston_2018_18_to_24_change_count.index, y=\"start_time\", data=boston_2018_18_to_24_change_count, ax=axes[3],palette=\"OrRd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_trip_geodata_clean[\"district_route\"] = boston_2018_trip_geodata_clean[\"district_start\"] + \",\" + boston_2018_trip_geodata_clean[\"district_end\"]\n",
    "boston_2018_trip_geodata_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2, figsize=(20, 10))\n",
    "\n",
    "axes[0][0].set_title(\"Destinations when starting in Boston\")\n",
    "axes[0][1].set_title(\"Destinations when starting in Cambridge\")\n",
    "axes[1][0].set_title(\"Destinations when starting in Somerville\")\n",
    "axes[1][1].set_title(\"Destinations when starting in Brookline\")\n",
    "sns.countplot(x=\"district_route\",data=boston_2018_trip_geodata_clean[boston_2018_trip_geodata_clean[\"district_start\"] == \"Boston\"], ax=axes[0][0],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_route\",data=boston_2018_trip_geodata_clean[boston_2018_trip_geodata_clean[\"district_start\"] == \"Cambridge\"], ax=axes[0][1],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_route\",data=boston_2018_trip_geodata_clean[boston_2018_trip_geodata_clean[\"district_start\"] == \"Somerville\"], ax=axes[1][0],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_route\",data=boston_2018_trip_geodata_clean[boston_2018_trip_geodata_clean[\"district_start\"] == \"Brookline\"], ax=axes[1][1],palette=\"OrRd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, sharey=True, figsize=(20, 10))\n",
    "\n",
    "axes[0].set_title(\"Subscriber starting districts\")\n",
    "axes[1].set_title(\"Customer starting districts\")\n",
    "sns.countplot(x=\"district_start\",data=boston_2018_trip_geodata_clean[boston_2018_trip_geodata_clean[\"user_type\"] == \"Subscriber\"], ax=axes[0],palette=\"OrRd\")\n",
    "sns.countplot(x=\"district_start\",data=boston_2018_trip_geodata_clean[boston_2018_trip_geodata_clean[\"user_type\"] == \"Customer\"], ax=axes[1],palette=\"OrRd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timelapse of monthly start locations visualized in a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_list = []\n",
    "\n",
    "for i in range(12):\n",
    "    heat_data2 = []\n",
    "    for element in boston_2018_trip_geodata_clean[boston_2018_trip_geodata_clean[\"month\"] == (i + 1)][\"start_coordinates\"]:\n",
    "        heat_data2.append([float(element[0]), float(element[1])])\n",
    "    coordinate_list.append(heat_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monthly_heat_map = folium.Map(location=(42.76507, -71.25371),  tiles='Stamen Toner', \n",
    "                       zoom_start=9, control_scale=True, max_zoom=20)\n",
    "\n",
    "monthly_heat_map.add_child(plugins.HeatMapWithTime(data=coordinate_list, use_local_extrema=False, radius=25))\n",
    "monthly_heat_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration (KPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime(x):\n",
    "    return datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "boston_2018_data_clean['datetime_start'] = boston_2018_data_clean['start_time'].apply(lambda x: get_datetime(x))\n",
    "boston_2018_data_clean['datetime_end'] = boston_2018_data_clean['end_time'].apply(lambda x: get_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_data_clean['duration'] = boston_2018_data_clean['datetime_end'] - boston_2018_data_clean['datetime_start']\n",
    "boston_2018_data_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seconds(x):\n",
    "    return x.total_seconds()\n",
    "\n",
    "boston_2018_data_clean['seconds'] = boston_2018_data_clean['duration'].apply(lambda x: get_seconds(x))\n",
    "boston_2018_data_clean.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_duration_per_trip = np.empty(24)\n",
    "total_duration_per_hour = np.empty(24)\n",
    "total_amount_of_trips = np.empty(24)\n",
    "for i in range(24):\n",
    "    total_duration_per_trip[i] = boston_2018_data_clean[boston_2018_data_clean[\"hour\"] == i][\"seconds\"].median()\n",
    "    total_duration_per_hour[i] = boston_2018_data_clean[boston_2018_data_clean[\"hour\"] == i][\"seconds\"].sum()\n",
    "    total_amount_of_trips[i] = boston_2018_data_clean[boston_2018_data_clean[\"hour\"] == i][\"seconds\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_amount_of_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_per_trip = np.divide(total_duration_per_trip, 60)\n",
    "duration_per_trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_duration_per_hour = np.divide(total_duration_per_hour, 60 * 60)\n",
    "total_duration_per_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "duration_per_trip_data = pd.DataFrame(duration_per_trip, columns=['minutes'])\n",
    "total_duration_per_hour_data = pd.DataFrame(total_duration_per_hour, columns=['hours'])\n",
    "amount_of_trips_data = pd.DataFrame(total_amount_of_trips, columns=['amount'])\n",
    "\n",
    "f, axes = plt.subplots(4, 1, figsize=(20, 20))\n",
    "\n",
    "sns.barplot(x = total_duration_per_hour_data.index , y=\"hours\", data=total_duration_per_hour_data, ax=axes[0],palette=\"OrRd\")\n",
    "axes[0].set_title(\"Total hours travelled per hour throughout the year (As a reference)\")\n",
    "sns.barplot(x = amount_of_trips_data.index , y=\"amount\", data=amount_of_trips_data, ax=axes[1],palette=\"OrRd\")\n",
    "axes[1].set_title(\"Amount of trips per hour throughout the year (As a reference)\")\n",
    "sns.barplot(x = duration_per_trip_data.index , y=\"minutes\", data=duration_per_trip_data, ax=axes[2],palette=\"OrRd\")\n",
    "axes[2].set_title(\"Median duration of trip per hour throughout the year (KPI)\")\n",
    "sns.boxplot(x = \"hour\", y = \"seconds\", data= boston_2018_data_clean, ax=axes[3], palette=\"OrRd\", showfliers=False)\n",
    "axes[3].set_title(\"Median duration of trip per hour throughout the year (KPI)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_counting = boston_2018_trip_geodata_with_temp_clean.groupby(\"date\").count()[\"start_time\"]\n",
    "date_grouping = boston_2018_trip_geodata_with_temp_clean.groupby([\"date\", \"hour\"]).count()\n",
    "#yp = yp.rename({\"start_time\": \"amount\"})\n",
    "date_grouping = date_grouping.reset_index(level=[0,1])\n",
    "date_grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_2018_trip_geodata_with_temp_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_hourly_data = boston_2018_trip_geodata_with_temp_clean.groupby([\"month\", \"weekday\", \"hour\"]).median()[[\"max_temp\", \"precip\"]]\n",
    "grouped_hourly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_amount_data = boston_2018_trip_geodata_with_temp_clean.groupby([\"month\", \"weekday\", \"hour\"]).count()[\"start_time\"]\n",
    "grouped_amount_data.rename(\"amount\", inplace=True)\n",
    "grouped_amount_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = pd.concat([grouped_hourly_data, grouped_amount_data], axis=1)\n",
    "grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boston_2018_trip_geodata_with_temp_clean = boston_2018_trip_geodata_with_temp_clean.merge(date_grouping[[\"date\", \"hour\", \"start_time\"]], how=\"inner\", left_on=[\"date\", \"hour\"], right_on=[\"date\", \"hour\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boston_2018_trip_geodata_with_temp_clean.rename(columns={\"start_time_x\": \"start_time\", \"start_time_y\" : \"amount\"}, inplace=True)\n",
    "#boston_2018_trip_geodata_with_temp_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_grouping[\"hour\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "# Plotting the data\n",
    "ax.scatter(date_grouping[\"hour\"].values, date_grouping[\"start_time\"].values, marker='x',)\n",
    "ax.set_xlabel(\"Hour\")\n",
    "ax.set_ylabel(\"Amount of bikes used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_poly_scikit(X,Y,d):\n",
    "    \n",
    "    # initialize PolynomialFeatures\n",
    "    poly_reg = PolynomialFeatures (degree = d)\n",
    "    \n",
    "    # Polynomial transformation\n",
    "    x_poly = poly_reg.fit_transform(X.reshape(-1,1))\n",
    "    \n",
    "    # Fitting linear regression to polynomial features\n",
    "    lin_reg_Poly = LinearRegression()\n",
    "    lin_reg_Poly.fit(x_poly, Y)\n",
    "    model_pred = lin_reg_Poly.predict(x_poly)\n",
    "    \n",
    "    # Plotting the regression line and the data (we have to transform the inputs as well!)\n",
    "    x_fit = np.arange(X.min(),X.max() ,1)[:, np.newaxis]\n",
    "    y_pred = lin_reg_Poly.predict(poly_reg.fit_transform(x_fit.reshape(-1,1)))\n",
    "    \n",
    "    plt.figure(figsize = (8,6))\n",
    "    plt.scatter(X,Y,marker=\"x\", c='C2')\n",
    "    ylim = plt.ylim()\n",
    "    plt.plot(x_fit,y_pred, c='C1')\n",
    "    plt.xlabel(\"Temperature (°C)\")\n",
    "    plt.ylabel(\"Demand (GW)\")\n",
    "    plt.xlim([X.min()-2,X.max()+2]) # leave some space before and after limits\n",
    "    plt.ylim(ylim)\n",
    "    print ('The R^2 for quadratic curve is: ',r2_score(Y, model_pred))\n",
    "    #print(lin_reg_Poly.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression_poly_scikit(date_grouping[\"hour\"].values, date_grouping[\"start_time\"].values, d = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_grouping = boston_2018_trip_geodata_with_temp_clean.groupby([\"date\",\"max_temp\"]).count()\n",
    "temp_grouping = temp_grouping.reset_index(level=[0,1])\n",
    "temp_grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "# Plotting the data\n",
    "ax.scatter(temp_grouping[\"max_temp\"], temp_grouping[\"start_time\"], marker='x',)\n",
    "ax.set_xlabel(\"Temperature\")\n",
    "ax.set_ylabel(\"Amount of bikes used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression_poly_scikit(temp_grouping[\"max_temp\"].values, temp_grouping[\"start_time\"].values, d = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = grouped_data.reset_index()\n",
    "grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "x_entire = grouped_data[[\"weekday\", \"hour\", \"month\", \"max_temp\", \"precip\"]]\n",
    "y_entire = grouped_data[\"amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = StandardScaler()\n",
    "x_entire_norm = norm.fit_transform(x_entire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_entire_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_entire_norm, y_entire, test_size=0.3,random_state=40)\n",
    "\n",
    "#lr.fit(x_train, y_train)\n",
    "# Different size ?????????????????????\n",
    "#x_train = x_entire.iloc[y_train_index]\n",
    "#y_train = y_entire.iloc[y_train_index]\n",
    "#x_test = x_entire.iloc[y_test_index]\n",
    "#y_test = y_entire.iloc[y_test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = lr.predict(x_test)   \n",
    "\n",
    "mae = mean_absolute_error(y_predict, y_test)\n",
    "mse = mean_squared_error(y_predict, y_test)\n",
    "determination = r2_score(y_predict, y_test)\n",
    "print(\"Mean absolute error: \", mae)\n",
    "print(\"Mean squared error: \", mse)\n",
    "print(\"R² = \", determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = svm.SVR()\n",
    "regr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = regr.predict(x_test)\n",
    "\n",
    "mae = mean_absolute_error(y_predict, y_test)\n",
    "mse = mean_squared_error(y_predict, y_test)\n",
    "determination = r2_score(y_predict, y_test)\n",
    "print(\"Mean absolute error: \", mae)\n",
    "print(\"Mean squared error: \", mse)\n",
    "print(\"R² = \", determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = Ridge(alpha = 0.01, normalize = True, solver = 'lsqr')\n",
    "ridge_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = ridge_reg.predict(x_test)\n",
    "\n",
    "mae = mean_absolute_error(y_predict, y_test)\n",
    "mse = mean_squared_error(y_predict, y_test)\n",
    "determination = r2_score(y_predict, y_test)\n",
    "print(\"Mean absolute error: \", mae)\n",
    "print(\"Mean squared error: \", mse)\n",
    "print(\"R² = \", determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg = Lasso(alpha = 1)\n",
    "lasso_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = lasso_reg.predict(x_test)\n",
    "\n",
    "mae = mean_absolute_error(y_predict, y_test)\n",
    "mse = mean_squared_error(y_predict, y_test)\n",
    "determination = r2_score(y_predict, y_test)\n",
    "print(\"Mean absolute error: \", mae)\n",
    "print(\"Mean squared error: \", mse)\n",
    "print(\"R² = \", determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_reg = KNeighborsRegressor(n_neighbors=9)\n",
    "KNN_model = KNN_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = KNN_model.predict(x_test)\n",
    "\n",
    "mae = mean_absolute_error(y_predict, y_test)\n",
    "mse = mean_squared_error(y_predict, y_test)\n",
    "determination = r2_score(y_predict, y_test)\n",
    "print(\"Mean absolute error: \", mae)\n",
    "print(\"Mean squared error: \", mse)\n",
    "print(\"R² = \", determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree_reg = DecisionTreeRegressor(max_depth=5)\n",
    "tree_model = Tree_reg.fit(x_train, y_train) \n",
    "\n",
    "# Predict\n",
    "y_hat_tree = tree_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = tree_model.predict(x_test)\n",
    "\n",
    "mae = mean_absolute_error(y_predict, y_test)\n",
    "mse = mean_squared_error(y_predict, y_test)\n",
    "determination = r2_score(y_predict, y_test)\n",
    "print(\"Mean absolute error: \", mae)\n",
    "print(\"Mean squared error: \", mse)\n",
    "print(\"R² = \", determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = LogisticRegression(C=1e3)   # C is a regularization term, we set it to 1000 here\n",
    "model_log.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model_log.predict(x_test)\n",
    "\n",
    "mae = mean_absolute_error(y_predict, y_test)\n",
    "mse = mean_squared_error(y_predict, y_test)\n",
    "determination = r2_score(y_predict, y_test)\n",
    "print(\"Mean absolute error: \", mae)\n",
    "print(\"Mean squared error: \", mse)\n",
    "print(\"R² = \", determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg=2\n",
    "model_svc = SVC(kernel='poly', C=100.0, degree=deg, coef0=1.0)\n",
    "model_svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model_svc.predict(x_test)\n",
    "\n",
    "mae = mean_absolute_error(y_predict, y_test)\n",
    "mse = mean_squared_error(y_predict, y_test)\n",
    "determination = r2_score(y_predict, y_test)\n",
    "print(\"Mean absolute error: \", mae)\n",
    "print(\"Mean squared error: \", mse)\n",
    "print(\"R² = \", determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1 / (len(np.array(x_train))\n",
    "             * np.array(x_train).var()) # scikit-learn uses gamma = 1/(n_features*X.var()) parameterization\n",
    "model_rbf = SVC(kernel='rbf', C=10.0, gamma=100000*gamma)\n",
    "model_rbf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model_rbf.predict(x_test)\n",
    "\n",
    "mae = mean_absolute_error(y_predict, y_test)\n",
    "mse = mean_squared_error(y_predict, y_test)\n",
    "determination = r2_score(y_predict, y_test)\n",
    "print(\"Mean absolute error: \", mae)\n",
    "print(\"Mean squared error: \", mse)\n",
    "print(\"R² = \", determination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
